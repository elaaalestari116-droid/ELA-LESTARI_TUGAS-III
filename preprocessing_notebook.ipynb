{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24210844",
   "metadata": {},
   "source": [
    "# Preprocessing Kredit Nasabah\n",
    "Notebook reproducing the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b63e70",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Load the dataset from the provided Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd47ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'/mnt/data/DATASET KREDIT NASABAH.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defad289",
   "metadata": {},
   "source": [
    "## 2. Inspect data\n",
    "Basic info and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae44607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0d843",
   "metadata": {},
   "source": [
    "## 3. Imputation (median for numeric, mode for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c31952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "num_imp = SimpleImputer(strategy='median')\n",
    "cat_imp = SimpleImputer(strategy='most_frequent')\n",
    "df[num_cols] = num_imp.fit_transform(df[num_cols])\n",
    "df[cat_cols] = cat_imp.fit_transform(df[cat_cols])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5ef82",
   "metadata": {},
   "source": [
    "## 4. Handling rare categories\n",
    "Combine categories with frequency < 1% into 'Lain-Lain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56342bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "for col in cat_cols:\n",
    "    freqs = df[col].value_counts(normalize=True)\n",
    "    rare = freqs[freqs < threshold].index.tolist()\n",
    "    if rare:\n",
    "        df[col] = df[col].apply(lambda x: 'Lain-Lain' if x in rare else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f66429",
   "metadata": {},
   "source": [
    "## 5. One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "enc = encoder.fit_transform(df[cat_cols])\n",
    "enc_cols = encoder.get_feature_names_out(cat_cols)\n",
    "df_enc = pd.concat([df.drop(columns=cat_cols).reset_index(drop=True), pd.DataFrame(enc, columns=enc_cols)], axis=1)\n",
    "df_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa4584",
   "metadata": {},
   "source": [
    "## 6. Outlier capping using IQR with multiplier 3 (Winsorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_enc.select_dtypes(include=['number']).columns:\n",
    "    Q1 = df_enc[col].quantile(0.25)\n",
    "    Q3 = df_enc[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 3*IQR\n",
    "    upper = Q3 + 3*IQR\n",
    "    df_enc[col] = df_enc[col].clip(lower=lower, upper=upper)\n",
    "df_enc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1adfe82",
   "metadata": {},
   "source": [
    "## 7. Scaling (StandardScaler) - fit on train only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df_enc.copy()\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "num_cols = X_train.select_dtypes(include=['number']).columns\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd4e96a",
   "metadata": {},
   "source": [
    "## 8. Save processed data and artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train_scaled.csv', index=False)\n",
    "X_test.to_csv('X_test_scaled.csv', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
